{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drawing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3Y24Q8CiNai"
      },
      "source": [
        "!pip install tensorflowjs \n",
        "#!mkdir model\n",
        "#!tensorflowjs_converter --input_format keras keras.h5 model/\n",
        "#!zip -r model.zip model \n",
        "#from google.colab import files\n",
        "#files.download('model.zip')\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "def download():\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')\n",
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 5000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load a subset of the data to memory \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splittext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "\n",
        "    #separate into training and testing \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names\n",
        "    x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "    x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "    x_train /= 255.0\n",
        "    x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "    # Define model\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(100, activation='softmax')) \n",
        "# Train model\n",
        "    adam = tf.train.AdamOptimizer()\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "    print(model.summary())\n",
        "\n",
        "   #fit the model \n",
        "    model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)\n",
        "\n",
        "#evaluate on unseen data\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))\n",
        "    model.save('keras.h5')\n",
        "    !mkdir model\n",
        "    !tensorflowjs_converter --input_format keras keras.h5 model/\n",
        "    !zip -r model.zip model \n",
        "    from google.colab import files\n",
        "    files.download('model.zip')\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJpRyurBd8nA"
      },
      "source": [
        ""
      ]
    }
  ]
}